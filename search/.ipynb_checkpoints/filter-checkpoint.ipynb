{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3af9775d-3bd6-4d18-bebc-2139a621687e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import numpy as np\n",
    "import pandas as pd\n",
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astroquery.gaia import Gaia\n",
    "from astroquery.simbad import Simbad\n",
    "from astroquery.vizier import Vizier\n",
    "from typing import Callable, Dict\n",
    "import os\n",
    "\n",
    "from auxiliary.filter_functions import filter_gaia, filter_archival, filter_chandra, filter_erosita, filter_ned, filter_simbad, filter_vizier, filter_Xray_binaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28548cab-b5b9-4746-888a-7ae1f7783441",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysing 2 detections from output/detections_w0.2_forward.txt\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "0: 4418 - gaia match: yes\n",
      "0: 4418 - archival match: no\n",
      "0: 4418 - chandra match: no\n",
      "0: 4418 - erosita match: no\n",
      "0: 4418 - ned match: yes\n",
      "0: 4418 - 'OTYPES'\n",
      "0: 4418 - vizier match: yes\n",
      "0: 4418 - xray-binaries match: no\n",
      "No new FXRT candidates found.\n"
     ]
    }
   ],
   "source": [
    "def safe_read_filtered(filename: str, catalogs: Dict[str, Callable], detections: pd.DataFrame = None) -> pd.DataFrame:\n",
    "    import os\n",
    "    if os.path.exists(filename):\n",
    "        return pd.read_csv(filename, sep=',', header=0, dtype=str)\n",
    "    else:\n",
    "        if detections is not None:\n",
    "            # use detections columns as a template\n",
    "            df = pd.DataFrame(columns=detections.columns)\n",
    "        else:\n",
    "            # fallback: minimal structure\n",
    "            df = pd.DataFrame(columns=['Number','ObsId','RA','DEC','THETA','POS_ERR','SIGNIFICANCE'])\n",
    "        return update_catalogs(df, catalogs)\n",
    "\n",
    "def update_catalogs(dataframe: pd.DataFrame, catalogs: Dict[str, Callable], verbose: int = 0) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    ## Return a new dataframe with the catalog match columns added.\n",
    "\n",
    "    ### Args:\n",
    "        dataframe `pd.DataFrame`: Dataframe to add the catalog match columns to.\n",
    "        catalogs `Dict[str, Callable]`: Catalogs to add to the dataframe.\n",
    "        verbose `int` (optional): Defaults to `0`. Level of verbosity.\n",
    "\n",
    "    ### Returns:\n",
    "        `pd.DataFrame`: Dataframe with the catalog match columns added.\n",
    "    \"\"\"\n",
    "    dataframe = dataframe.copy()\n",
    "\n",
    "    for catalog, _ in catalogs.items():\n",
    "        if f'{catalog}_match' not in dataframe.columns:\n",
    "            dataframe.insert(len(dataframe.columns),\n",
    "                             f'{catalog}_match', 'unknown')\n",
    "\n",
    "            if verbose > 2:\n",
    "                print(f'Added {catalog}_match column.')\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "def update_detections(detections: pd.DataFrame, filtered: pd.DataFrame, catalogs: Dict[str, Callable], verbose: int = 0) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    ## Adds new detections to the filtered dataframe.\n",
    "\n",
    "    ### Args:\n",
    "        detections `pd.DataFrame`: Dataframe of detections to add to the filtered dataframe.\n",
    "        filtered `pd.DataFrame`: Dataframe of filtered detections.\n",
    "        catalogs `Dict[str, Callable]`: Dictionary of catalogs to add to the dataframe.\n",
    "\n",
    "    ### Returns:\n",
    "        `pd.DataFrame`: The updated filtered dataframe with new detections added.\n",
    "    \"\"\"\n",
    "    detections = detections.copy()\n",
    "    filtered = filtered.copy()\n",
    "\n",
    "    detections = update_catalogs(detections, catalogs)\n",
    "    filtered = update_catalogs(filtered, catalogs)\n",
    "\n",
    "    # add new detections to filtered dataframe\n",
    "    for i, detection in detections.iterrows():\n",
    "        if (\n",
    "            detection.at['ObsId'] in filtered['ObsId'].values and\n",
    "            detection.at['RA'] in filtered['RA'].values and\n",
    "            detection.at['DEC'] in filtered['DEC'].values and\n",
    "            detection.at['THETA'] in filtered['THETA'].values and\n",
    "            detection.at['POS_ERR'] in filtered['POS_ERR'].values and\n",
    "            detection.at['SIGNIFICANCE'] in filtered['SIGNIFICANCE'].values\n",
    "        ):\n",
    "            if verbose > 2:\n",
    "                print(\n",
    "                    f'{i}: {detection.at[\"ObsId\"]} - Detection already in filtered.')\n",
    "            continue\n",
    "\n",
    "        filtered.loc[len(filtered)] = detection\n",
    "\n",
    "        if verbose > 2:\n",
    "            print(\n",
    "                f'{i}: {detection.at[\"ObsId\"]} - Added detection to filtered.')\n",
    "\n",
    "    return filtered\n",
    "\n",
    "\n",
    "def filter_detections(detections: pd.DataFrame, filtered: pd.DataFrame, catalogs: Dict[str, Callable], verbose: int = 0) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    ## Filter the detections in the detections dataframe.\n",
    "\n",
    "    ### Args:\n",
    "        detections `pd.DataFrame`: Dataframe of detections to filter.\n",
    "        filtered `pd.DataFrame`: Dataframe of filtered detections.\n",
    "        catalogs `Dict[str, Callable]`: Catalogs to filter the detections with.\n",
    "        verbose `int` (optional): Defaults to `0`. Level of verbosity.\n",
    "\n",
    "    ### Returns:\n",
    "        `pd.DataFrame`: Filtered dataframe of detections.\n",
    "    \"\"\"\n",
    "    # add new detections to filtered dataframe\n",
    "    filtered = update_detections(detections, filtered, catalogs, verbose)\n",
    "\n",
    "    # to check if detection has already been queried\n",
    "    # TODO: make this a more permanent solution\n",
    "    ref_file = f'output/filtered_{WINDOW}_forward.csv'\n",
    "    filtered_ref = safe_read_filtered(ref_file, catalogs, detections)\n",
    "\n",
    "    for i, detection in filtered.iterrows():\n",
    "        # check if detection is in the filtered_ref file\n",
    "        if detection['RA'] in filtered_ref['RA'].values and detection['DEC'] in filtered_ref['DEC'].values:\n",
    "            filtered_detection = filtered_ref[(filtered_ref['RA'] == detection['RA']) &\n",
    "                                              (filtered_ref['DEC'] == detection['DEC'])].iloc[0]\n",
    "            # populate the new filtered file with the previously filtered detection\n",
    "            for catalog in catalogs.keys():\n",
    "                if filtered_detection[f'{catalog}_match'] != 'unknown':\n",
    "                    filtered.at[i, f'{catalog}_match'] = filtered_detection[f'{catalog}_match']\n",
    "            if verbose > 1:\n",
    "                print(f'{i}: {detection.at[\"ObsId\"]} - populated from {ref_file}.')\n",
    "            continue\n",
    "\n",
    "        for catalog, filter_func in catalogs.items():\n",
    "            if detection.at[f'{catalog}_match'] == 'unknown':\n",
    "                try:\n",
    "                    result = 'yes' if filter_func(detection) else 'no'\n",
    "                    filtered.at[i, f'{catalog}_match'] = result\n",
    "\n",
    "                    if verbose > 1:\n",
    "                        print(f'{i}: {detection.at[\"ObsId\"]} - {catalog} match: {filtered.at[i, f\"{catalog}_match\"]}')\n",
    "                except Exception as e:\n",
    "                    print(f'{i}: {detection.at[\"ObsId\"]} - {e}')\n",
    "                    continue\n",
    "            else:\n",
    "                if verbose > 1:\n",
    "                    print(f'{i}: {detection.at[\"ObsId\"]} - {catalog} match: already known.')\n",
    "\n",
    "    return filtered\n",
    "\n",
    "\n",
    "\n",
    "def filter_detection_file(detections_filename: str, filtered_filename: str, catalogs: Dict[str, Callable], verbose: int = 0) -> None:\n",
    "    \"\"\"\n",
    "    ## Filter the detections in the detections file.\n",
    "\n",
    "    ### Args:\n",
    "        detections_filename `str`: Filename of the detections file.\n",
    "        filtered_filename `str`: Filename of the filtered file.\n",
    "        catalogs `Dict[str, Callable]`: Catalogs to filter the detections with.\n",
    "        verbose `int` (optional): Defaults to `0`. Level of verbosity.\n",
    "    \"\"\"\n",
    "    detections = pd.read_csv(\n",
    "        detections_filename,\n",
    "        sep=r\"\\s+\",   # split on one or more spaces\n",
    "        engine=\"python\",\n",
    "        names=[\"ObsId\", \"RA\", \"DEC\", \"THETA\", \"POS_ERR\", \"SIGNIFICANCE\"],\n",
    "        header=0,     # skip the first line (\"ObsId\")\n",
    "        dtype=str\n",
    "    )\n",
    " \n",
    "\n",
    "    filtered   = safe_read_filtered(filtered_filename, catalogs, detections)\n",
    "\n",
    "    if verbose > 0:\n",
    "        print(\n",
    "            f'Analysing {len(detections)} detections from {detections_filename}'\n",
    "        )\n",
    "\n",
    "    filtered = filter_detections(detections, filtered, catalogs, verbose)\n",
    "\n",
    "    filtered.to_csv(filtered_filename, index=False)\n",
    "\n",
    "\n",
    "def clear_filter_matches(filtered_filename: str, catalog: str) -> None:\n",
    "    \"\"\"\n",
    "    ## Clear the matches for a specific catalog in the filtered file.\n",
    "\n",
    "    ### Args:\n",
    "        filtered_filename `str`: Filename of the filtered file.\n",
    "        catalog `str`: Catalog to clear the matches for.\n",
    "    \"\"\"\n",
    "    filtered = pd.read_csv(filtered_filename, sep=',', header=0, dtype=str)\n",
    "\n",
    "    for i, detection in filtered.iterrows():\n",
    "        if f'{catalog}_match' in filtered.columns:\n",
    "            filtered.at[i, f'{catalog}_match'] = 'unknown'\n",
    "    \n",
    "    filtered.to_csv(filtered_filename, index=False)\n",
    "\n",
    "def find_new_fxrt(filtered_filename: str, catalogs: Dict[str, Callable], window: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    ## Find new FXRT candidates (detections with no catalog matches).\n",
    "\n",
    "    ### Args:\n",
    "        filtered_filename `str`: Path to the filtered detections CSV.\n",
    "        catalogs `Dict[str, Callable]`: Dictionary of catalogs used.\n",
    "        window `str`: Window size label (e.g. \"w0.2\") for naming the output file.\n",
    "\n",
    "    ### Returns:\n",
    "        `pd.DataFrame`: DataFrame with rows that are potential new FXRTs.\n",
    "    \"\"\"\n",
    "    filtered = pd.read_csv(filtered_filename, sep=\",\", header=0, dtype=str, index_col=0)\n",
    "\n",
    "    # build list of catalog match columns\n",
    "    catalog_cols = [f\"{cat}_match\" for cat in catalogs.keys()]\n",
    "\n",
    "    # condition: all catalogs = \"no\"\n",
    "    new_fxrt = filtered.loc[(filtered[catalog_cols] == \"no\").all(axis=1)]\n",
    "\n",
    "    if len(new_fxrt) == 0:\n",
    "        print(\"No new FXRT candidates found.\")\n",
    "    else:\n",
    "        print(f\"Found {len(new_fxrt)} new FXRT candidate(s).\")\n",
    "\n",
    "        # make sure directory exists\n",
    "        os.makedirs(\"output/candidates\", exist_ok=True)\n",
    "\n",
    "        # save candidates to dedicated folder\n",
    "        out_file = f\"output/candidates/new_fxrt_{window}.csv\"\n",
    "        new_fxrt.to_csv(out_file, index=False)\n",
    "        print(f\"Saved candidates to {out_file}\")\n",
    "\n",
    "        # also print table to console\n",
    "        print(new_fxrt)\n",
    "\n",
    "    return new_fxrt\n",
    "\n",
    "\n",
    "WINDOW = \"w0.2\"\n",
    "\n",
    "DETECTIONS_FILENAME = f'output/detections_{WINDOW}_forward.txt'\n",
    "FILTERED_FILENAME   = f'output/filtered_{WINDOW}_forward.csv'\n",
    "\n",
    "CATALOGS = {\n",
    "    'gaia': filter_gaia,\n",
    "    'archival': filter_archival,\n",
    "    'chandra': filter_chandra,\n",
    "    'erosita': filter_erosita,\n",
    "    'ned': filter_ned,\n",
    "    'simbad': filter_simbad,\n",
    "    'vizier': filter_vizier,\n",
    "    'xray-binaries': filter_Xray_binaries\n",
    "}\n",
    "VERBOSE = 2\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    filter_detection_file(\n",
    "        DETECTIONS_FILENAME,\n",
    "        FILTERED_FILENAME,\n",
    "        CATALOGS,\n",
    "        VERBOSE\n",
    "    )\n",
    "\n",
    "    #find and save new candidates \n",
    "    candidates = find_new_fxrt(FILTERED_FILENAME, CATALOGS, WINDOW)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CIAO 4.17",
   "language": "python",
   "name": "ciao"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
